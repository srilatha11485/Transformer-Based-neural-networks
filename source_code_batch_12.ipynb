{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":25036,"status":"ok","timestamp":1664958951032,"user":{"displayName":"srilatha mathangi","userId":"05834365901469890006"},"user_tz":-330},"id":"H9Kd2K2wSLMD","outputId":"1a4a60c8-26b5-4c0b-c70c-56bd080358b2"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive') "]},{"cell_type":"markdown","metadata":{"id":"t3MpdZUEk4iJ"},"source":["# **INSTALLATION AND IMPORTS**"]},{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":9692,"status":"ok","timestamp":1664958960713,"user":{"displayName":"srilatha mathangi","userId":"05834365901469890006"},"user_tz":-330},"id":"hKuuI5CL6jQp","outputId":"4a27f2db-1a94-43bf-9899-af7c09f4ae54"},"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting transformers\n","  Downloading transformers-4.22.2-py3-none-any.whl (4.9 MB)\n","\u001b[K     |████████████████████████████████| 4.9 MB 32.8 MB/s \n","\u001b[?25hRequirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (6.0)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.21.6)\n","Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers) (4.12.0)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.8.0)\n","Collecting tokenizers!=0.11.3,<0.13,>=0.11.1\n","  Downloading tokenizers-0.12.1-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (6.6 MB)\n","\u001b[K     |████████████████████████████████| 6.6 MB 46.9 MB/s \n","\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n","Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.64.1)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2022.6.2)\n","Collecting huggingface-hub<1.0,>=0.9.0\n","  Downloading huggingface_hub-0.10.0-py3-none-any.whl (163 kB)\n","\u001b[K     |████████████████████████████████| 163 kB 60.2 MB/s \n","\u001b[?25hRequirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (21.3)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0,>=0.9.0->transformers) (4.1.1)\n","Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->transformers) (3.0.9)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers) (3.8.1)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2022.6.15)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n","Installing collected packages: tokenizers, huggingface-hub, transformers\n","Successfully installed huggingface-hub-0.10.0 tokenizers-0.12.1 transformers-4.22.2\n"]}],"source":["!pip install transformers"]},{"cell_type":"code","execution_count":3,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":415},"executionInfo":{"elapsed":5594,"status":"ok","timestamp":1664958966264,"user":{"displayName":"srilatha mathangi","userId":"05834365901469890006"},"user_tz":-330},"id":"KPusQKNbfh0g","outputId":"012baf2d-b9a1-4c94-c0ba-005f59cbe060"},"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting anvil-uplink\n","  Downloading anvil_uplink-0.4.0-py2.py3-none-any.whl (88 kB)\n","\u001b[K     |████████████████████████████████| 88 kB 7.4 MB/s \n","\u001b[?25hRequirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from anvil-uplink) (1.15.0)\n","Collecting argparse\n","  Downloading argparse-1.4.0-py2.py3-none-any.whl (23 kB)\n","Collecting ws4py\n","  Downloading ws4py-0.5.1.tar.gz (51 kB)\n","\u001b[K     |████████████████████████████████| 51 kB 258 kB/s \n","\u001b[?25hRequirement already satisfied: future in /usr/local/lib/python3.7/dist-packages (from anvil-uplink) (0.16.0)\n","Building wheels for collected packages: ws4py\n","  Building wheel for ws4py (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for ws4py: filename=ws4py-0.5.1-py3-none-any.whl size=45229 sha256=4763e6da1585f7fbc3ff87258bec8cb186a37b9a27905a18951cc92ba5b607fb\n","  Stored in directory: /root/.cache/pip/wheels/29/ea/7d/3410aa0aa0e4402ead9a7a97ab2214804887e0f5c2b76f0c96\n","Successfully built ws4py\n","Installing collected packages: ws4py, argparse, anvil-uplink\n","Successfully installed anvil-uplink-0.4.0 argparse-1.4.0 ws4py-0.5.1\n"]},{"output_type":"display_data","data":{"application/vnd.colab-display-data+json":{"pip_warning":{"packages":["argparse","google"]}}},"metadata":{}}],"source":["!pip install anvil-uplink"]},{"cell_type":"code","execution_count":4,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":3623,"status":"ok","timestamp":1664958969877,"user":{"displayName":"srilatha mathangi","userId":"05834365901469890006"},"user_tz":-330},"id":"mVxUWFCuuQ3w","outputId":"d7186df7-00f4-49c4-d312-0e488b5c5f38"},"outputs":[{"output_type":"stream","name":"stdout","text":["Connecting to wss://anvil.works/uplink\n","Anvil websocket open\n","Connected to \"Default environment\" as SERVER\n"]}],"source":["import pandas as pd\n","import numpy as np\n","import tensorflow as tf\n","import time\n","import re\n","import pickle\n","import transformers\n","import collections\n","import warnings\n","import anvil.server\n","warnings.filterwarnings(\"ignore\")\n","def warn(*args, **kwargs):\n","    pass\n","warnings.warn = warn\n","\n","anvil.server.connect('36HRIW6HZ3N257K6IP6QUECM-URT6IC7IPZJ3RXCO')"]},{"cell_type":"markdown","metadata":{"id":"9vemxMAKldwl"},"source":["# **POSITIONAL ENCODING**"]},{"cell_type":"code","execution_count":5,"metadata":{"executionInfo":{"elapsed":46,"status":"ok","timestamp":1664958969879,"user":{"displayName":"srilatha mathangi","userId":"05834365901469890006"},"user_tz":-330},"id":"6gEuxS1wooXr"},"outputs":[],"source":["def get_angles(position, i, d_model):\n","    angle_rates = 1 / np.power(10000, (2 * (i // 2)) / np.float32(d_model))\n","    return position * angle_rates\n","\n","def positional_encoding(position, d_model):\n","    angle_rads = get_angles(\n","        np.arange(position)[:, np.newaxis],\n","        np.arange(d_model)[np.newaxis, :],\n","        d_model\n","    )\n","\n","    # apply sin to even indices in the array; 2i\n","    angle_rads[:, 0::2] = np.sin(angle_rads[:, 0::2])\n","\n","    # apply cos to odd indices in the array; 2i+1\n","    angle_rads[:, 1::2] = np.cos(angle_rads[:, 1::2])\n","\n","    pos_encoding = angle_rads[np.newaxis, ...]\n","\n","    return tf.cast(pos_encoding, dtype=tf.float32)\n"]},{"cell_type":"markdown","metadata":{"id":"YWr3Fe_dl-Jd"},"source":["# **MASKING**"]},{"cell_type":"code","execution_count":6,"metadata":{"executionInfo":{"elapsed":46,"status":"ok","timestamp":1664958969880,"user":{"displayName":"srilatha mathangi","userId":"05834365901469890006"},"user_tz":-330},"id":"pODt7KT4o99e"},"outputs":[],"source":["def create_padding_mask(seq):\n","    seq = tf.cast(tf.math.equal(seq, 0), tf.float32)\n","    # add extra dimensions to add the padding\n","    # to the attention logits.\n","    return seq[:, tf.newaxis, tf.newaxis, :] # (batch_size, 1, 1, seq_len)\n","\n","def create_look_ahead_mask(size):\n","    mask = 1 - tf.linalg.band_part(tf.ones((size, size)), -1, 0)\n","    return mask # (seq_len, seq_len)"]},{"cell_type":"markdown","metadata":{"id":"XLCS-LNjmJzH"},"source":["# **SELF ATTENTION**"]},{"cell_type":"code","execution_count":7,"metadata":{"executionInfo":{"elapsed":46,"status":"ok","timestamp":1664958969882,"user":{"displayName":"srilatha mathangi","userId":"05834365901469890006"},"user_tz":-330},"id":"cOc-inNQpEv3"},"outputs":[],"source":["def scaled_dot_product_attention(q, k, v, mask):\n","\n","    matmul_qk = tf.matmul(q, k, transpose_b=True) # (..., seq_len_q, seq_len_k)\n","    \n","    # scale matmul_qk\n","    dk = tf.cast(tf.shape(k)[-1], tf.float32)\n","    scaled_attention_logits = matmul_qk / tf.math.sqrt(dk)\n","    \n","    # add the mask to the scaled tensor.\n","    if mask is not None:\n","        scaled_attention_logits += (mask * -1e9)  \n","    # softmax is normalized on the last axis (seq_len_k) so that the scores\n","    # add up to 1.\n","    attention_weights = tf.nn.softmax(scaled_attention_logits, axis=-1) # (..., seq_len_q, seq_len_k)\n","\n","    output = tf.matmul(attention_weights, v) # (..., seq_len_q, depth_v)\n","    return output, attention_weights"]},{"cell_type":"markdown","metadata":{"id":"Twma7B6smZQv"},"source":["# **MULTI HEAD ATTENTION**"]},{"cell_type":"code","execution_count":8,"metadata":{"executionInfo":{"elapsed":45,"status":"ok","timestamp":1664958969883,"user":{"displayName":"srilatha mathangi","userId":"05834365901469890006"},"user_tz":-330},"id":"J8SJ3JlnpJAb"},"outputs":[],"source":["class MultiHeadAttention(tf.keras.layers.Layer):\n","    def __init__(self, d_model, num_heads):\n","        super(MultiHeadAttention, self).__init__()\n","        self.num_heads = num_heads\n","        self.d_model = d_model\n","\n","        assert d_model % self.num_heads == 0\n","\n","        self.depth = d_model // self.num_heads\n","\n","        self.wq = tf.keras.layers.Dense(d_model)\n","        self.wk = tf.keras.layers.Dense(d_model)\n","        self.wv = tf.keras.layers.Dense(d_model)\n","\n","        self.dense = tf.keras.layers.Dense(d_model)\n","        \n","    def split_heads(self, x, batch_size):\n","        \"\"\"Split the last dimension into (num_heads, depth).\n","    Transpose the result such that the shape is (batch_size, num_heads, seq_len, depth)\n","    \"\"\"\n","        x = tf.reshape(x, (batch_size, -1, self.num_heads, self.depth))\n","        return tf.transpose(x, perm=[0, 2, 1, 3])\n","    \n","    def call(self, v, k, q, mask):\n","        batch_size = tf.shape(q)[0]\n","\n","        q = self.wq(q)   # (batch_size, seq_len, d_model)\n","        k = self.wk(k)   # (batch_size, seq_len, d_model)\n","        v = self.wv(v)   # (batch_size, seq_len, d_model) \n","\n","        q = self.split_heads(q, batch_size) # (batch_size, num_heads, seq_len_q, depth)\n","        k = self.split_heads(k, batch_size) # (batch_size, num_heads, seq_len_q, depth)\n","        v = self.split_heads(v, batch_size) # (batch_size, num_heads, seq_len_q, depth)\n","\n","        scaled_attention, attention_weights = scaled_dot_product_attention(\n","            q, k, v, mask)\n","\n","        scaled_attention = tf.transpose(scaled_attention, perm=[0, 2, 1, 3])\n","\n","        concat_attention = tf.reshape(scaled_attention, (batch_size, -1, self.d_model))\n","        output = self.dense(concat_attention)\n","            \n","        return output, attention_weights"]},{"cell_type":"markdown","metadata":{"id":"EYpvHO_fmmU6"},"source":["# **FEED FORWARD NEURAL NETWORK**"]},{"cell_type":"code","execution_count":9,"metadata":{"executionInfo":{"elapsed":45,"status":"ok","timestamp":1664958969885,"user":{"displayName":"srilatha mathangi","userId":"05834365901469890006"},"user_tz":-330},"id":"goh8daBjpOJ8"},"outputs":[],"source":["def point_wise_feed_forward_network(d_model, dff):\n","    return tf.keras.Sequential([\n","        tf.keras.layers.Dense(dff, activation='relu'),\n","        tf.keras.layers.Dense(d_model)\n","    ])"]},{"cell_type":"markdown","metadata":{"id":"CNOU_ROtmvXh"},"source":["# **ENCODER LAYER**"]},{"cell_type":"code","execution_count":10,"metadata":{"executionInfo":{"elapsed":45,"status":"ok","timestamp":1664958969886,"user":{"displayName":"srilatha mathangi","userId":"05834365901469890006"},"user_tz":-330},"id":"rN3N3PbbpUkK"},"outputs":[],"source":["class EncoderLayer(tf.keras.layers.Layer):\n","    def __init__(self, d_model, num_heads, dff, rate=0.1):\n","        super(EncoderLayer, self).__init__()\n","\n","        self.mha = MultiHeadAttention(d_model, num_heads)\n","        self.ffn = point_wise_feed_forward_network(d_model, dff)\n","\n","        self.layernorm1 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n","        self.layernorm2 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n","\n","        self.dropout1 = tf.keras.layers.Dropout(rate)\n","        self.dropout2 = tf.keras.layers.Dropout(rate)\n","    \n","    def call(self, x, training, mask):\n","        attn_output, _ = self.mha(x, x, x, mask)\n","        attn_output = self.dropout1(attn_output, training=training)\n","        out1 = self.layernorm1(x + attn_output)\n","\n","        ffn_output = self.ffn(out1)\n","        ffn_output = self.dropout2(ffn_output, training=training)\n","        out2 = self.layernorm2(out1 + ffn_output)\n","\n","        return out2\n"]},{"cell_type":"markdown","metadata":{"id":"0teSZoITm1wJ"},"source":["# **DECODER LAYER**"]},{"cell_type":"code","execution_count":11,"metadata":{"executionInfo":{"elapsed":45,"status":"ok","timestamp":1664958969888,"user":{"displayName":"srilatha mathangi","userId":"05834365901469890006"},"user_tz":-330},"id":"53u3CWalpXso"},"outputs":[],"source":["class DecoderLayer(tf.keras.layers.Layer):\n","    def __init__(self, d_model, num_heads, dff, rate=0.1):\n","        super(DecoderLayer, self).__init__()\n","\n","        self.mha1 = MultiHeadAttention(d_model, num_heads)\n","        self.mha2 = MultiHeadAttention(d_model, num_heads)\n","\n","        self.ffn = point_wise_feed_forward_network(d_model, dff)\n","\n","        self.layernorm1 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n","        self.layernorm2 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n","        self.layernorm3 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n","\n","        self.dropout1 = tf.keras.layers.Dropout(rate)\n","        self.dropout2 = tf.keras.layers.Dropout(rate)\n","        self.dropout3 = tf.keras.layers.Dropout(rate)\n","    \n","    \n","    def call(self, x, enc_output, training, look_ahead_mask, padding_mask):\n","        attn1, attn_weights_block1 = self.mha1(x, x, x, look_ahead_mask)\n","        attn1 = self.dropout1(attn1, training=training)\n","        out1 = self.layernorm1(attn1 + x)\n","\n","        attn2, attn_weights_block2 = self.mha2(enc_output, enc_output, out1, padding_mask)\n","        attn2 = self.dropout2(attn2, training=training)\n","        out2 = self.layernorm2(attn2 + out1)\n","\n","        ffn_output = self.ffn(out2)\n","        ffn_output = self.dropout3(ffn_output, training=training)\n","        out3 = self.layernorm3(ffn_output + out2)\n","\n","        return out3, attn_weights_block1, attn_weights_block2\n"]},{"cell_type":"markdown","metadata":{"id":"qLJsMxaYm6Tp"},"source":["# **ENCODER**\n"]},{"cell_type":"code","execution_count":12,"metadata":{"executionInfo":{"elapsed":45,"status":"ok","timestamp":1664958969889,"user":{"displayName":"srilatha mathangi","userId":"05834365901469890006"},"user_tz":-330},"id":"PRfoRgW7pabs"},"outputs":[],"source":["class Encoder(tf.keras.layers.Layer):\n","    def __init__(self, num_layers, d_model, num_heads, dff, input_vocab_size, maximum_position_encoding, rate=0.1):\n","        super(Encoder, self).__init__()\n","\n","        self.d_model = d_model\n","        self.num_layers = num_layers\n","\n","        self.embedding = tf.keras.layers.Embedding(input_vocab_size, d_model)\n","        self.pos_encoding = positional_encoding(maximum_position_encoding, self.d_model)\n","\n","        self.enc_layers = [EncoderLayer(d_model, num_heads, dff, rate) for _ in range(num_layers)]\n","\n","        self.dropout = tf.keras.layers.Dropout(rate)\n","        \n","    def call(self, x, training, mask):\n","        seq_len = tf.shape(x)[1]\n","\n","        x = self.embedding(x)\n","        x *= tf.math.sqrt(tf.cast(self.d_model, tf.float32))\n","        x += self.pos_encoding[:, :seq_len, :]\n","\n","        x = self.dropout(x, training=training)\n","    \n","        for i in range(self.num_layers):\n","            x = self.enc_layers[i](x, training, mask)\n","    \n","        return x\n"]},{"cell_type":"markdown","metadata":{"id":"d8Yww00dnMxR"},"source":["# **DECODER**"]},{"cell_type":"code","execution_count":13,"metadata":{"executionInfo":{"elapsed":44,"status":"ok","timestamp":1664958969890,"user":{"displayName":"srilatha mathangi","userId":"05834365901469890006"},"user_tz":-330},"id":"uGcd7NYbpccl"},"outputs":[],"source":["class Decoder(tf.keras.layers.Layer):\n","    def __init__(self, num_layers, d_model, num_heads, dff, target_vocab_size, maximum_position_encoding, rate=0.1):\n","        super(Decoder, self).__init__()\n","\n","        self.d_model = d_model\n","        self.num_layers = num_layers\n","\n","        self.embedding = tf.keras.layers.Embedding(target_vocab_size, d_model)\n","        self.pos_encoding = positional_encoding(maximum_position_encoding, d_model)\n","\n","        self.dec_layers = [DecoderLayer(d_model, num_heads, dff, rate) for _ in range(num_layers)]\n","        self.dropout = tf.keras.layers.Dropout(rate)\n","    \n","    def call(self, x, enc_output, training, look_ahead_mask, padding_mask):\n","        seq_len = tf.shape(x)[1]\n","        attention_weights = {}\n","\n","        x = self.embedding(x)\n","        x *= tf.math.sqrt(tf.cast(self.d_model, tf.float32))\n","        x += self.pos_encoding[:, :seq_len, :]\n","\n","        x = self.dropout(x, training=training)\n","\n","        for i in range(self.num_layers):\n","            x, block1, block2 = self.dec_layers[i](x, enc_output, training, look_ahead_mask, padding_mask)\n","\n","            attention_weights['decoder_layer{}_block1'.format(i+1)] = block1\n","            attention_weights['decoder_layer{}_block2'.format(i+1)] = block2\n","    \n","        return x, attention_weights\n"]},{"cell_type":"markdown","metadata":{"id":"_TaieEifnRFB"},"source":["# **TRANSFORMER**\n"]},{"cell_type":"code","execution_count":14,"metadata":{"executionInfo":{"elapsed":45,"status":"ok","timestamp":1664958969892,"user":{"displayName":"srilatha mathangi","userId":"05834365901469890006"},"user_tz":-330},"id":"ZrTc72XCpeUt"},"outputs":[],"source":["class Transformer(tf.keras.Model):\n","    def __init__(self, num_layers, d_model, num_heads, dff, input_vocab_size, target_vocab_size, pe_input, pe_target, rate=0.1):\n","        super(Transformer, self).__init__()\n","\n","        self.encoder = Encoder(num_layers, d_model, num_heads, dff, input_vocab_size, pe_input, rate)\n","\n","        self.decoder = Decoder(num_layers, d_model, num_heads, dff, target_vocab_size, pe_target, rate)\n","        \n","        self.lstm = tf.keras.layers.LSTM(num_layers)\n","\n","        self.max_pool_2d = tf.keras.layers.MaxPooling2D(pool_size=(2, 2), strides=(1, 1), padding='same')\n","        self.final_layer = tf.keras.layers.Dense(target_vocab_size)\n","    \n","    def call(self, inp, tar, training, enc_padding_mask, look_ahead_mask, dec_padding_mask):\n","        enc_output = self.encoder(inp, training, enc_padding_mask)\n","\n","        dec_output, attention_weights = self.decoder(tar, enc_output, training, look_ahead_mask, dec_padding_mask)\n","      \n","        op=self.lstm(dec_output)\n","\n","        attention_weights['decoder_layer1_block1']=self.max_pool_2d(attention_weights['decoder_layer1_block1'])\n","\n","        final_output = self.final_layer(dec_output)\n","        \n","        return final_output, attention_weights,op\n","\n"]},{"cell_type":"markdown","metadata":{"id":"7Ri4YQSunl8S"},"source":["#  **SET HYPERPARAMETERS**"]},{"cell_type":"code","execution_count":15,"metadata":{"executionInfo":{"elapsed":45,"status":"ok","timestamp":1664958969893,"user":{"displayName":"srilatha mathangi","userId":"05834365901469890006"},"user_tz":-330},"id":"5L8k_Zp5oDqG"},"outputs":[],"source":["# hyper-params\n","num_layers = 4\n","d_model = 128  \n","dff = 512\n","num_heads = 8\n","EPOCHS = 20 "]},{"cell_type":"markdown","metadata":{"id":"Mg7SyrVRoGq9"},"source":["# **OPTIMIZER**"]},{"cell_type":"code","execution_count":16,"metadata":{"executionInfo":{"elapsed":45,"status":"ok","timestamp":1664958969894,"user":{"displayName":"srilatha mathangi","userId":"05834365901469890006"},"user_tz":-330},"id":"V5HHejsnpktj"},"outputs":[],"source":["class CustomSchedule(tf.keras.optimizers.schedules.LearningRateSchedule):\n","    def __init__(self, d_model, warmup_steps=4000):\n","        super(CustomSchedule, self).__init__()\n","\n","        self.d_model = d_model\n","        self.d_model = tf.cast(self.d_model, tf.float32)\n","\n","        self.warmup_steps = warmup_steps\n","    \n","    def __call__(self, step):\n","        arg1 = tf.math.rsqrt(step)\n","        arg2 = step * (self.warmup_steps ** -1.5)\n","\n","        return tf.math.rsqrt(self.d_model) * tf.math.minimum(arg1, arg2)\n","\n","learning_rate = CustomSchedule(d_model)\n","optimizer = tf.keras.optimizers.Adam(learning_rate, beta_1=0.9, beta_2=0.98, epsilon=1e-9)\n","loss_object = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True, reduction='none')\n","\n"]},{"cell_type":"markdown","metadata":{"id":"nJOGFUutobgN"},"source":["# **LOSS AND METRIC**"]},{"cell_type":"code","execution_count":17,"metadata":{"executionInfo":{"elapsed":45,"status":"ok","timestamp":1664958969895,"user":{"displayName":"srilatha mathangi","userId":"05834365901469890006"},"user_tz":-330},"id":"ZJdJNdlDp-un"},"outputs":[],"source":["def loss_function(real, pred):\n","    mask = tf.math.logical_not(tf.math.equal(real, 0))\n","    loss_ = loss_object(real, pred)\n","\n","    mask = tf.cast(mask, dtype=loss_.dtype)\n","    loss_ *= mask\n","\n","    return tf.reduce_sum(loss_)/tf.reduce_sum(mask)\n","\n","train_loss = tf.keras.metrics.Mean(name='train_loss')\n"]},{"cell_type":"code","execution_count":18,"metadata":{"executionInfo":{"elapsed":45,"status":"ok","timestamp":1664958969896,"user":{"displayName":"srilatha mathangi","userId":"05834365901469890006"},"user_tz":-330},"id":"d_SfzucNt2ji"},"outputs":[],"source":["def create_masks(inp, tar):\n","    enc_padding_mask = create_padding_mask(inp)\n","    dec_padding_mask = create_padding_mask(inp)\n","\n","    look_ahead_mask = create_look_ahead_mask(tf.shape(tar)[1])\n","    dec_target_padding_mask = create_padding_mask(tar)\n","    combined_mask = tf.maximum(dec_target_padding_mask, look_ahead_mask)\n","  \n","    return enc_padding_mask, combined_mask, dec_padding_mask\n"]},{"cell_type":"markdown","metadata":{"id":"WeqYTKfIYVH8"},"source":["# **LOADING DATASET**"]},{"cell_type":"code","execution_count":19,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":505,"status":"ok","timestamp":1664958970357,"user":{"displayName":"srilatha mathangi","userId":"05834365901469890006"},"user_tz":-330},"id":"8PiURsnO6nXz","outputId":"dde61abe-bb78-4844-b0d4-3fb7e87d4c18"},"outputs":[{"output_type":"stream","name":"stdout","text":["env: DATA_DIR=./data/squad\n","--2022-10-05 08:36:09--  https://rajpurkar.github.io/SQuAD-explorer/dataset/train-v2.0.json\n","Resolving rajpurkar.github.io (rajpurkar.github.io)... 185.199.108.153, 185.199.109.153, 185.199.110.153, ...\n","Connecting to rajpurkar.github.io (rajpurkar.github.io)|185.199.108.153|:443... connected.\n","HTTP request sent, awaiting response... 200 OK\n","Length: 42123633 (40M) [application/json]\n","Saving to: ‘./data/squad/train-v2.0.json’\n","\n","train-v2.0.json     100%[===================>]  40.17M  --.-KB/s    in 0.1s    \n","\n","2022-10-05 08:36:09 (280 MB/s) - ‘./data/squad/train-v2.0.json’ saved [42123633/42123633]\n","\n","--2022-10-05 08:36:09--  https://rajpurkar.github.io/SQuAD-explorer/dataset/dev-v2.0.json\n","Resolving rajpurkar.github.io (rajpurkar.github.io)... 185.199.108.153, 185.199.109.153, 185.199.110.153, ...\n","Connecting to rajpurkar.github.io (rajpurkar.github.io)|185.199.108.153|:443... connected.\n","HTTP request sent, awaiting response... 200 OK\n","Length: 4370528 (4.2M) [application/json]\n","Saving to: ‘./data/squad/dev-v2.0.json’\n","\n","dev-v2.0.json       100%[===================>]   4.17M  --.-KB/s    in 0.01s   \n","\n","2022-10-05 08:36:09 (279 MB/s) - ‘./data/squad/dev-v2.0.json’ saved [4370528/4370528]\n","\n"]}],"source":["%env DATA_DIR=./data/squad \n","\n","# downloading the SQuAD dataset\n","def download_squad(version=1):\n","    if version == 1:\n","        !wget -P $DATA_DIR https://rajpurkar.github.io/SQuAD-explorer/dataset/train-v1.1.json\n","        !wget -P $DATA_DIR https://rajpurkar.github.io/SQuAD-explorer/dataset/dev-v1.1.json\n","    else:\n","        !wget -P $DATA_DIR https://rajpurkar.github.io/SQuAD-explorer/dataset/train-v2.0.json\n","        !wget -P $DATA_DIR https://rajpurkar.github.io/SQuAD-explorer/dataset/dev-v2.0.json\n","            \n","download_squad(version=2)\n"]},{"cell_type":"markdown","metadata":{"id":"WzV2Y0U-IYA9"},"source":["# **PROCESSOR**"]},{"cell_type":"code","execution_count":20,"metadata":{"executionInfo":{"elapsed":2980,"status":"ok","timestamp":1664958973331,"user":{"displayName":"srilatha mathangi","userId":"05834365901469890006"},"user_tz":-330},"id":"QO5U0L2S6uOH"},"outputs":[],"source":["from transformers.data.processors.squad import SquadV2Processor"]},{"cell_type":"code","execution_count":21,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":79424,"status":"ok","timestamp":1664959052746,"user":{"displayName":"srilatha mathangi","userId":"05834365901469890006"},"user_tz":-330},"id":"7HSUPyYk6uIz","outputId":"f82d6fc6-cf7e-46f9-8e89-882683dcb7f4"},"outputs":[{"output_type":"stream","name":"stderr","text":["100%|██████████| 35/35 [00:06<00:00,  5.12it/s]\n"]},{"output_type":"stream","name":"stdout","text":["validation 11873\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 442/442 [01:10<00:00,  6.27it/s]"]},{"output_type":"stream","name":"stdout","text":["train 130319\n"]},{"output_type":"stream","name":"stderr","text":["\n"]}],"source":["# this processor loads the SQuAD2.0 dev set examples\n","# The processors can be used for loading datasets and converting their examples to features for direct use in the model.\n","processor = SquadV2Processor()\n","examples = processor.get_dev_examples(\"./data/squad/\", filename=\"dev-v2.0.json\")\n","print(\"validation \"+str(len(examples)))\n","#/content/data/squad/train-v2.0.json\n","examplestrain = processor.get_train_examples(\"./data/squad/\", filename=\"train-v2.0.json\")\n","print(\"train \"+str(len(examplestrain)))"]},{"cell_type":"code","execution_count":22,"metadata":{"executionInfo":{"elapsed":51,"status":"ok","timestamp":1664959052748,"user":{"displayName":"srilatha mathangi","userId":"05834365901469890006"},"user_tz":-330},"id":"TRiy3waO6uA9"},"outputs":[],"source":["# generate some maps to help us identify examples of interest\n","qid_to_example_index = {example.qas_id: i for i, example in enumerate(examples)}\n","qid_to_has_answer = {example.qas_id: bool(example.answers) for example in examples}\n","answer_qids = [qas_id for qas_id, has_answer in qid_to_has_answer.items() if has_answer]\n","no_answer_qids = [qas_id for qas_id, has_answer in qid_to_has_answer.items() if not has_answer]\n","\n","qid_to_example_index_train = {example.qas_id: i for i, example in enumerate(examplestrain)}\n","qid_to_has_answer_train = {example.qas_id: bool(example.answers) for example in examplestrain}\n","answer_qids_train = [qas_id for qas_id, has_answer in qid_to_has_answer_train.items() if has_answer]   #changed by me \n","no_answer_qids_train = [qas_id for qas_id, has_answer in qid_to_has_answer_train.items() if not has_answer]"]},{"cell_type":"code","execution_count":23,"metadata":{"executionInfo":{"elapsed":50,"status":"ok","timestamp":1664959052749,"user":{"displayName":"srilatha mathangi","userId":"05834365901469890006"},"user_tz":-330},"id":"iutPxLpL6t6P"},"outputs":[],"source":["#It dsplays the Question and Context of a sample from dataset\n","def extract(idx, train = True):    \n","    from pprint import pprint\n","    a = \"\"\n","    if train:\n","      # idx = qid_to_example_index_train[qid]\n","      q = examplestrain[idx].question_text\n","      c = examplestrain[idx].context_text\n","      for answer in examplestrain[idx].answers:\n","        a = answer['text']\n","    else:\n","      # idx = qid_to_example_index[qid]\n","      q = examples[idx].question_text\n","      c = examples[idx].context_text\n","      for answer in examples[idx].answers:\n","        a = answer['text']\n","    qna = \"<CLS>\" + q + \"<SEP>\" + a\n","    return c[:100], qna"]},{"cell_type":"code","execution_count":24,"metadata":{"executionInfo":{"elapsed":49,"status":"ok","timestamp":1664959052750,"user":{"displayName":"srilatha mathangi","userId":"05834365901469890006"},"user_tz":-330},"id":"RLXfzpGG64aR"},"outputs":[],"source":["def generate_dataset():\n","  context_train = []\n","  qna_train = []\n","  context_test = []\n","  qna_test = []\n","  for i in range(len(examplestrain)):\n","    c,qna = extract(i,train=True)\n","    context_train.append(c)\n","    qna_train.append(qna)\n","  for i in range(len(examples)):\n","    c,qna = extract(i,train=False)\n","    context_test.append(c)\n","    qna_test.append(qna)\n","  return context_train, qna_train, context_test, qna_test"]},{"cell_type":"code","execution_count":25,"metadata":{"executionInfo":{"elapsed":683,"status":"ok","timestamp":1664959053387,"user":{"displayName":"srilatha mathangi","userId":"05834365901469890006"},"user_tz":-330},"id":"xkWXtN9r64qG"},"outputs":[],"source":["context_train, qna_train, context_test, qna_test = generate_dataset()"]},{"cell_type":"markdown","metadata":{"id":"9THpAkBY4Nuj"},"source":["# **TOKENIZATION**"]},{"cell_type":"code","execution_count":26,"metadata":{"executionInfo":{"elapsed":6,"status":"ok","timestamp":1664959053388,"user":{"displayName":"srilatha mathangi","userId":"05834365901469890006"},"user_tz":-330},"id":"7TqbpEyPMRqa"},"outputs":[],"source":["# since < and > from default tokens cannot be removed\n","filters = '!\"#$%&()*+,-./:;=?@[\\\\]^_`{|}~\\t\\n'\n","oov_token = '<unk>'"]},{"cell_type":"code","execution_count":27,"metadata":{"executionInfo":{"elapsed":7,"status":"ok","timestamp":1664959053389,"user":{"displayName":"srilatha mathangi","userId":"05834365901469890006"},"user_tz":-330},"id":"cHw2csoYImsa"},"outputs":[],"source":["context_tokenizer = tf.keras.preprocessing.text.Tokenizer(oov_token=oov_token)\n","qna_tokenizer = tf.keras.preprocessing.text.Tokenizer(filters=filters, oov_token=oov_token)"]},{"cell_type":"code","execution_count":28,"metadata":{"executionInfo":{"elapsed":4344,"status":"ok","timestamp":1664959057727,"user":{"displayName":"srilatha mathangi","userId":"05834365901469890006"},"user_tz":-330},"id":"DWU9Xu7OKVab"},"outputs":[],"source":["context_tokenizer.fit_on_texts(context_train)\n","qna_tokenizer.fit_on_texts(qna_train)"]},{"cell_type":"code","execution_count":29,"metadata":{"executionInfo":{"elapsed":1243,"status":"ok","timestamp":1664959058928,"user":{"displayName":"srilatha mathangi","userId":"05834365901469890006"},"user_tz":-330},"id":"3ESm-aYR-tvx"},"outputs":[],"source":["samples = 10000\n","inputs = context_tokenizer.texts_to_sequences(context_train[:samples])\n","targets = qna_tokenizer.texts_to_sequences(qna_train[:samples])"]},{"cell_type":"code","execution_count":30,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":16,"status":"ok","timestamp":1664959058929,"user":{"displayName":"srilatha mathangi","userId":"05834365901469890006"},"user_tz":-330},"id":"KoizyBvLKv8h","outputId":"34932cbc-a2bb-4aad-8c2c-ad5a2f775587"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["(31525, 48975)"]},"metadata":{},"execution_count":30}],"source":["encoder_vocab_size = len(context_tokenizer.word_index) + 1\n","decoder_vocab_size = len(qna_tokenizer.word_index) + 1\n","\n","# vocab_size\n","encoder_vocab_size, decoder_vocab_size"]},{"cell_type":"code","execution_count":31,"metadata":{"executionInfo":{"elapsed":14,"status":"ok","timestamp":1664959058930,"user":{"displayName":"srilatha mathangi","userId":"05834365901469890006"},"user_tz":-330},"id":"cVeMilXr-bpC"},"outputs":[],"source":["# maxlen\n","# taking values > and round figured to 75th percentile\n","# at the same time not leaving high variance\n","encoder_maxlen = 100\n","decoder_maxlen = 75"]},{"cell_type":"code","execution_count":32,"metadata":{"executionInfo":{"elapsed":15,"status":"ok","timestamp":1664959058931,"user":{"displayName":"srilatha mathangi","userId":"05834365901469890006"},"user_tz":-330},"id":"Q8fy38CxCNf_"},"outputs":[],"source":["transformer = Transformer(\n","    num_layers, \n","    d_model, \n","    num_heads, \n","    dff,\n","    encoder_vocab_size, \n","    decoder_vocab_size, \n","    pe_input=encoder_vocab_size, \n","    pe_target=decoder_vocab_size,\n",")"]},{"cell_type":"markdown","metadata":{"id":"niLUeuA9-ou1"},"source":["# **CHECKPOINTS**"]},{"cell_type":"code","execution_count":33,"metadata":{"executionInfo":{"elapsed":15,"status":"ok","timestamp":1664959058932,"user":{"displayName":"srilatha mathangi","userId":"05834365901469890006"},"user_tz":-330},"id":"P4KgKld2IHX5"},"outputs":[],"source":["path = \"/content/drive/MyDrive/QnA/\"\n","checkpoint_path = path + \"model/checkpoints/\"\n","\n","ckpt = tf.train.Checkpoint(transformer=transformer, optimizer=optimizer)\n","\n","ckpt_manager = tf.train.CheckpointManager(ckpt, checkpoint_path, max_to_keep=5)\n","\n","if ckpt_manager.latest_checkpoint:\n","    ckpt.restore(ckpt_manager.latest_checkpoint)\n","    print ('Latest checkpoint restored!!')"]},{"cell_type":"markdown","metadata":{"id":"FeDzubIJ8l73"},"source":["# **PADDING/TRUNCATING the sequence for identical sequence lengths**"]},{"cell_type":"code","execution_count":34,"metadata":{"executionInfo":{"elapsed":15,"status":"ok","timestamp":1664959058933,"user":{"displayName":"srilatha mathangi","userId":"05834365901469890006"},"user_tz":-330},"id":"vEyUBeu7ACRt"},"outputs":[],"source":["inputs = tf.keras.preprocessing.sequence.pad_sequences(inputs, maxlen=encoder_maxlen, padding='post', truncating='post')\n","targets = tf.keras.preprocessing.sequence.pad_sequences(targets, maxlen=decoder_maxlen, padding='post', truncating='post')"]},{"cell_type":"markdown","metadata":{"id":"M_mfuDyz88ok"},"source":["# **CREATE DATASET PIPELINE**"]},{"cell_type":"code","execution_count":35,"metadata":{"executionInfo":{"elapsed":16,"status":"ok","timestamp":1664959058934,"user":{"displayName":"srilatha mathangi","userId":"05834365901469890006"},"user_tz":-330},"id":"LzO6l3-AB7hJ"},"outputs":[],"source":["inputs = tf.cast(inputs, dtype=tf.int32)\n","targets = tf.cast(targets, dtype=tf.int32)"]},{"cell_type":"code","execution_count":36,"metadata":{"executionInfo":{"elapsed":15,"status":"ok","timestamp":1664959058934,"user":{"displayName":"srilatha mathangi","userId":"05834365901469890006"},"user_tz":-330},"id":"slZ5f4P4DurS"},"outputs":[],"source":["BUFFER_SIZE = 4000 #20000 the maximum number elements that will be buffered when prefetching.\n","BATCH_SIZE = 64"]},{"cell_type":"code","execution_count":37,"metadata":{"executionInfo":{"elapsed":16,"status":"ok","timestamp":1664959058935,"user":{"displayName":"srilatha mathangi","userId":"05834365901469890006"},"user_tz":-330},"id":"wI-fV7eABWN6"},"outputs":[],"source":["dataset = tf.data.Dataset.from_tensor_slices((inputs, targets)).shuffle(BUFFER_SIZE).batch(BATCH_SIZE)"]},{"cell_type":"markdown","metadata":{"id":"yjk0aTyZ-a56"},"source":["# **TRAINING STEPS**"]},{"cell_type":"code","execution_count":38,"metadata":{"executionInfo":{"elapsed":16,"status":"ok","timestamp":1664959058936,"user":{"displayName":"srilatha mathangi","userId":"05834365901469890006"},"user_tz":-330},"id":"xmVOMzkrczgl"},"outputs":[],"source":["@tf.function\n","def train_step(inp, tar):\n","    tar_inp = tar[:, :-1]\n","    tar_real = tar[:, 1:]\n","\n","    enc_padding_mask, combined_mask, dec_padding_mask = create_masks(inp, tar_inp)\n","\n","    with tf.GradientTape() as tape:\n","        predictions,_,_ = transformer(\n","            inp, tar_inp, \n","            True, \n","            enc_padding_mask, \n","            combined_mask, \n","            dec_padding_mask\n","        )\n","        loss = loss_function(tar_real, predictions)\n","\n","    gradients = tape.gradient(loss, transformer.trainable_variables)    \n","    optimizer.apply_gradients(zip(gradients, transformer.trainable_variables))\n","\n","    train_loss(loss)"]},{"cell_type":"code","execution_count":41,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":380},"executionInfo":{"elapsed":431197,"status":"error","timestamp":1664960748326,"user":{"displayName":"srilatha mathangi","userId":"05834365901469890006"},"user_tz":-330},"id":"xORKpv69dSW5","outputId":"b434cae2-c488-4e8a-e4e1-d378138c397d"},"outputs":[{"output_type":"error","ename":"KeyboardInterrupt","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-41-8855779f9f7d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     10\u001b[0m   \u001b[0mtrain_loss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreset_states\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m   \u001b[0;32mfor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0minp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtar\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m       \u001b[0mtrain_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtar\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;36m10\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m       \u001b[0mckpt_save_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mckpt_manager\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/util/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    913\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    914\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 915\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    916\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    917\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    945\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    946\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 947\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    948\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    949\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2955\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[1;32m   2956\u001b[0m     return graph_function._call_flat(\n\u001b[0;32m-> 2957\u001b[0;31m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[0m\u001b[1;32m   2958\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2959\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1852\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1853\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1854\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1855\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1856\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    502\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    503\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 504\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    505\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    506\u001b[0m           outputs = execute.execute_with_cancellation(\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     53\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 55\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     56\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}],"source":["import warnings\n","warnings.filterwarnings(\"ignore\")\n","def warn(*args, **kwargs):\n","    pass\n","warnings.warn = warn\n","\n","EPOCHS = 2\n","for epoch in range(EPOCHS):\n","  start = time.time()\n","  train_loss.reset_states()\n","  for (batch, (inp, tar)) in enumerate(dataset):\n","      train_step(inp, tar)\n","  if (epoch + 1) % 10 == 0:\n","      ckpt_save_path = ckpt_manager.save()\n","      print ('Saving checkpoint for epoch {} at {}'.format(epoch+1, ckpt_save_path))\n","  print ('Epoch {} Loss {:.4f}'.format(epoch + 1, train_loss.result()))\n","  print ('Time taken for 1 epoch: {} secs\\n'.format(time.time() - start))\n","\n"]},{"cell_type":"markdown","metadata":{"id":"wDlHwid2bRZg"},"source":["# **PREDICTION**"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":56,"status":"aborted","timestamp":1664960056404,"user":{"displayName":"srilatha mathangi","userId":"05834365901469890006"},"user_tz":-330},"id":"PqWFSYK4F9va"},"outputs":[],"source":["model_dir = \"/content/drive/MyDrive/QnA-20210324T144643Z-001/QnA/model/\""]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":56,"status":"aborted","timestamp":1664960056405,"user":{"displayName":"srilatha mathangi","userId":"05834365901469890006"},"user_tz":-330},"id":"ECdys6xV_RRh"},"outputs":[],"source":["# Loading our trained model\n","with open(model_dir + 'model.pkl', 'rb') as fp:\n","    model = pickle.load(fp)\n","with open(model_dir + 'tokenizer.pkl', 'rb') as fp:\n","    tokenizer = pickle.load(fp)"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":57,"status":"aborted","timestamp":1664960056407,"user":{"displayName":"srilatha mathangi","userId":"05834365901469890006"},"user_tz":-330},"id":"ZcmzpaxgbaRq"},"outputs":[],"source":["# ----------------- Helper functions for get_robust_prediction ----------------- #\n","def to_list(tensor):\n","  return tensor.detach().cpu().tolist()\n","\n","def get_qa_inputs(example, tokenizer):\n","    # load the example, convert to inputs, get model outputs\n","    question = example.question_text\n","    context = example.context_text\n","    return tokenizer.encode_plus(question, context, return_tensors='pt')\n","\n","def get_clean_text(tokens, tokenizer):\n","    text = tokenizer.convert_tokens_to_string(\n","        tokenizer.convert_ids_to_tokens(tokens)\n","        )\n","    # Clean whitespace\n","    text = text.strip()\n","    text = \" \".join(text.split())\n","    return text\n","\n","# compute the probability of each prediction - nice but not necessary\n","def prediction_probabilities(predictions):\n","\n","    def softmax(x):\n","        \"\"\"Compute softmax values for each sets of scores in x.\"\"\"\n","        e_x = np.exp(x - np.max(x))\n","        return e_x / e_x.sum()\n","\n","    all_scores = [pred.start_logit+pred.end_logit for pred in predictions] \n","    return softmax(np.array(all_scores))\n","\n","\n","# get sensible preliminary predictions, sorted by score\n","def preliminary_predictions(start_logits, end_logits, input_ids, nbest):\n","    # convert tensors to lists\n","    start_logits = to_list(start_logits)[0]\n","    end_logits = to_list(end_logits)[0]\n","    tokens = to_list(input_ids)[0]\n","\n","    # sort our start and end logits from largest to smallest, keeping track of the index\n","    start_idx_and_logit = sorted(enumerate(start_logits), key=lambda x: x[1], reverse=True)\n","    end_idx_and_logit = sorted(enumerate(end_logits), key=lambda x: x[1], reverse=True)\n","    \n","    start_indexes = [idx for idx, logit in start_idx_and_logit[:nbest]]\n","    end_indexes = [idx for idx, logit in end_idx_and_logit[:nbest]]\n","\n","    # question tokens are between the CLS token (101, at position 0) and first SEP (102) token \n","    question_indexes = [i+1 for i, token in enumerate(tokens[1:tokens.index(102)])]\n","\n","    # keep track of all preliminary predictions\n","    PrelimPrediction = collections.namedtuple(  # pylint: disable=invalid-name\n","        \"PrelimPrediction\", [\"start_index\", \"end_index\", \"start_logit\", \"end_logit\"]\n","    )\n","    prelim_preds = []\n","    for start_index in start_indexes:\n","        for end_index in end_indexes:\n","            # throw out invalid predictions\n","            if start_index in question_indexes:\n","                continue\n","            if end_index in question_indexes:\n","                continue\n","            if end_index < start_index:\n","                continue\n","            prelim_preds.append(\n","                PrelimPrediction(\n","                    start_index = start_index,\n","                    end_index = end_index,\n","                    start_logit = start_logits[start_index],\n","                    end_logit = end_logits[end_index]\n","                )\n","            )\n","    # sort prelim_preds in descending score order\n","    prelim_preds = sorted(prelim_preds, key=lambda x: (x.start_logit + x.end_logit), reverse=True)\n","    return prelim_preds\n","\n","# narrow that down to the top nbest predictions\n","def best_predictions(prelim_preds, nbest, tokenizer, tokens, start_logits, end_logits):\n","    # keep track of all best predictions\n","\n","    # This will be the pool from which answer probabilities are computed \n","    BestPrediction = collections.namedtuple(\n","        \"BestPrediction\", [\"text\", \"start_logit\", \"end_logit\"]\n","    )\n","    nbest_predictions = []\n","    seen_predictions = []\n","    for pred in prelim_preds:\n","        if len(nbest_predictions) >= nbest: \n","            break\n","        if pred.start_index > 0: # non-null answers have start_index > 0\n","\n","            toks = tokens[pred.start_index : pred.end_index+1]\n","            text = get_clean_text(toks, tokenizer)\n","            # print(f'Text is :{text}')\n","\n","            # if this text has been seen already - skip it\n","            if text in seen_predictions:\n","                continue\n","\n","            # flag text as being seen\n","            seen_predictions.append(text) \n","\n","            # add this text to a pruned list of the top nbest predictions\n","            nbest_predictions.append(\n","                BestPrediction(\n","                    text=text, \n","                    start_logit=pred.start_logit,\n","                    end_logit=pred.end_logit\n","                    )\n","                )\n","        \n","    # Add the null prediction\n","    nbest_predictions.append(\n","        BestPrediction(\n","            text=\"\", \n","            start_logit=start_logits[0], \n","            end_logit=end_logits[0]\n","            )\n","        )\n","    return nbest_predictions\n","\n","# compute score difference\n","def compute_score_difference(predictions):\n","    \"\"\" Assumes that the null answer is always the last prediction \"\"\"\n","    score_null = predictions[-1].start_logit + predictions[-1].end_logit\n","    score_non_null = predictions[0].start_logit + predictions[0].end_logit\n","    return score_null - score_non_null"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":56,"status":"aborted","timestamp":1664960056408,"user":{"displayName":"srilatha mathangi","userId":"05834365901469890006"},"user_tz":-330},"id":"l-7Gq1pwyZua"},"outputs":[],"source":["# Inference on given quesion and context\n","@anvil.server.callable\n","def get_robust_prediction_qna(question, context,  nbest=10, null_threshold=1.0, verbose=False):\n","    \n","    inputs = tokenizer.encode_plus(question, context, return_tensors='pt')\n","    # pprint(inputs)\n","    outputs = model(**inputs)\n","    # pprint(outputs)\n","    start_logits, end_logits = outputs.start_logits, outputs.end_logits\n","\n","    # pprint(tokens)\n","    # get sensible preliminary predictions, sorted by score\n","    prelim_preds = preliminary_predictions(start_logits, \n","                                           end_logits, \n","                                           inputs['input_ids'],\n","                                           nbest)\n","    # pprint(prelim_preds)\n","    # narrow that down to the top nbest predictions\n","    tokens = to_list(inputs['input_ids'])[0]\n","    start_logits = to_list(start_logits)[0]\n","    end_logits = to_list(end_logits)[0]\n","    nbest_preds = best_predictions(prelim_preds, nbest, tokenizer, tokens, start_logits, end_logits)\n","    # pprint(nbest_preds)\n","    # compute the probability of each prediction - nice but not necessary\n","    probabilities = prediction_probabilities(nbest_preds)\n","        \n","    # compute score difference\n","    score_difference = compute_score_difference(nbest_preds)\n","\n","    # return nbest_preds, probabilities\n","    # if score difference > threshold, return the null answer\n","    if score_difference > null_threshold:\n","        return \"\", probabilities[-1]\n","    else:\n","      if verbose:\n","        prob_answer = {}\n","        for i,p in enumerate(probabilities):\n","          prob_answer[p] = nbest_preds[i].text\n","        return prob_answer\n","      else:\n","        return nbest_preds[0].text, probabilities[0]"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"j8YPC-iqgh5Q","executionInfo":{"status":"aborted","timestamp":1664960056409,"user_tz":-330,"elapsed":57,"user":{"displayName":"srilatha mathangi","userId":"05834365901469890006"}}},"outputs":[],"source":["anvil.server.wait_forever()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"g0RkA4lr3VMJ","executionInfo":{"status":"aborted","timestamp":1664960056410,"user_tz":-330,"elapsed":57,"user":{"displayName":"srilatha mathangi","userId":"05834365901469890006"}}},"outputs":[],"source":["q='what is your favourite place?'\n","c='i hate raspberry'\n","get_robust_prediction_qna(q,c)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"fqpUahsSyccK","executionInfo":{"status":"aborted","timestamp":1664960056412,"user_tz":-330,"elapsed":54,"user":{"displayName":"srilatha mathangi","userId":"05834365901469890006"}}},"outputs":[],"source":["q = \"When did lincoln born?\"\n","c = \"Abraham Lincoln was born on February 12, 1809, in Hardin County, Kentucky, to Thomas and Nancy Lincoln in their one room log cabin on their farm for a living known as Sinking Spring (near modern-day Hodgenville, Kentucky). Although Thomas lacked formal education, he was an excellent farmer and carpenter, and often times served as a member of the jury. Thomas and Nancy joined a small Baptist church in the area that had broken away from the larger church over the issue of slavery.\"\n","#View only the top prediction when verbose = False by default\n","get_robust_prediction_qna(q,c)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"-_IiLHQbYPZp","executionInfo":{"status":"aborted","timestamp":1664960056413,"user_tz":-330,"elapsed":54,"user":{"displayName":"srilatha mathangi","userId":"05834365901469890006"}}},"outputs":[],"source":["#View all the nbest outputs with thier probability when verbose = True\n","get_robust_prediction_qna(q,c, verbose=True)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"wIQB7TGUdC1e","executionInfo":{"status":"aborted","timestamp":1664960056414,"user_tz":-330,"elapsed":55,"user":{"displayName":"srilatha mathangi","userId":"05834365901469890006"}}},"outputs":[],"source":["q = \"where is the church?\"\n","c = \"The Candelária Church is a famous historic Roman Catholic church in central Rio de Janeiro, Brazil. The church itself and the buildings around it in Pius X Square became known as a popular location for possibly hundreds of Rio de Janeiro's street children to form a makeshift home at night. The church's personnel provides food, shelter, education and religious advice to as many of these children as possible. Many of the homeless children are involved with the illegal drug trade and prostitution, and because many of these children also live around the church during the day, police keep a constant watch on the church's surroundings. \"\n","get_robust_prediction_qna(q,c)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"scZ6oDm3dXgf","executionInfo":{"status":"aborted","timestamp":1664960056416,"user_tz":-330,"elapsed":56,"user":{"displayName":"srilatha mathangi","userId":"05834365901469890006"}}},"outputs":[],"source":["q = \"who won the match?\"\n","c = \"With the wicket of Pat Cummins, Joe Root (Eng) took his 12th catch of the tournament, surpassing Ricky Ponting's record of 11 he set in 2003. This was Australia's first World Cup semi-final defeat in eight appearances, england won the match.\"\n","get_robust_prediction_qna(q,c)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"JQzLHAr1bknu","executionInfo":{"status":"aborted","timestamp":1664960056417,"user_tz":-330,"elapsed":57,"user":{"displayName":"srilatha mathangi","userId":"05834365901469890006"}}},"outputs":[],"source":["q = \"what is his nationality?\"\n","c = \" his mother tongue is german \"\n","get_robust_prediction_qna(q,c)"]},{"cell_type":"markdown","metadata":{"id":"Ht_59JBDHHwS"},"source":["# METRICS"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"yPt7RlxhI65B","executionInfo":{"status":"aborted","timestamp":1664960056418,"user_tz":-330,"elapsed":57,"user":{"displayName":"srilatha mathangi","userId":"05834365901469890006"}}},"outputs":[],"source":["import torch\n","# given a question id (qas_id or qid), load the example, get the model outputs and generate an answer\n","def get_prediction(qid):\n","    \n","    question = examples[qid_to_example_index[qid]].question_text\n","    context = examples[qid_to_example_index[qid]].context_text\n","\n","    inputs = tokenizer.encode_plus(question, context, return_tensors='pt')\n","    outputs = model(**inputs)\n","    \n","    answer_start = torch.argmax(outputs[0])  # get the most likely beginning of answer with the argmax of the score\n","    answer_end = torch.argmax(outputs[1]) + 1 \n","\n","    answer = tokenizer.convert_tokens_to_string(tokenizer.convert_ids_to_tokens(inputs['input_ids'][0][answer_start:answer_end]))\n","\n","    return answer\n","\n","#Removing articles and punctuation, and standardizing whitespace are all typical text processing steps.\n","def normalize_text(s):    \n","    import string, re\n","\n","    def remove_articles(text):\n","        regex = re.compile(r\"\\b(a|an|the)\\b\", re.UNICODE)\n","        return re.sub(regex, \" \", text)\n","\n","    def white_space_fix(text):\n","        return \" \".join(text.split())\n","\n","    def remove_punc(text):\n","        exclude = set(string.punctuation)\n","        return \"\".join(ch for ch in text if ch not in exclude)\n","\n","    def lower(text):\n","        return text.lower()\n","\n","    return white_space_fix(remove_articles(remove_punc(lower(s))))\n","\n","# check if the prediction and truth are extacly matching\n","def compute_exact_match(prediction, truth):\n","    return int(normalize_text(prediction) == normalize_text(truth))\n","\n","# compute f1 score using precision and recal based on number of common tokens in prediction and truth,\n","# and also number of predicte and truth tokens\n","def F1(prediction, truth):\n","    pred_tokens = normalize_text(prediction).split()\n","    truth_tokens = normalize_text(truth).split()\n","    \n","    # if either the prediction or the truth is no-answer then f1 = 1 if they agree, 0 otherwise\n","    if len(pred_tokens) == 0 or len(truth_tokens) == 0:\n","        return int(pred_tokens == truth_tokens)\n","    \n","    common_tokens = set(pred_tokens) & set(truth_tokens)\n","    \n","    # if there are no common tokens then f1 = 0\n","    if len(common_tokens) == 0:\n","        return 0\n","    \n","    a = len(common_tokens) / len(pred_tokens) #precision\n","    b = len(common_tokens) / len(truth_tokens) #recall\n","    \n","    return  2*(a * b) / (a + b)\n","\n","# helper function that retrieves all possible true answers from a squad2.0 example\n","def get_gold_answers(example):\n","    gold_answers = [answer[\"text\"] for answer in example.answers if answer[\"text\"]]\n","\n","    # if gold_answers doesn't exist it's because this is a negative example - \n","    # the only correct answer is an empty string\n","    if not gold_answers:\n","        gold_answers = [\"\"]\n","        \n","    return gold_answers\n","\n","#POSITIVE EXAMPLE-----\n","prediction = get_prediction(answer_qids[100])\n","example = examples[qid_to_example_index[answer_qids[100]]]\n","\n","gold_answers = get_gold_answers(example)\n","\n","em_score = max((compute_exact_match(prediction, answer)) for answer in gold_answers)\n","f1_score = max((F1(prediction, answer)) for answer in gold_answers)\n","\n","print(f\"Question: {example.question_text}\")\n","print(f\"Prediction: {prediction}\")\n","print(f\"True Answers: {gold_answers}\")\n","print(f\"EM: {em_score} \\t F1: {f1_score}\")\n","\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"mCMJ8aIa_rfx","executionInfo":{"status":"aborted","timestamp":1664960056419,"user_tz":-330,"elapsed":57,"user":{"displayName":"srilatha mathangi","userId":"05834365901469890006"}}},"outputs":[],"source":["print(len(answer_qids))\n","print(len(answer_qids_train))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"uh6Ph0RLFSjr","executionInfo":{"status":"aborted","timestamp":1664960056420,"user_tz":-330,"elapsed":58,"user":{"displayName":"srilatha mathangi","userId":"05834365901469890006"}}},"outputs":[],"source":["print(len(answer_qids))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"BZ4qHoq7ymwf","executionInfo":{"status":"aborted","timestamp":1664960056422,"user_tz":-330,"elapsed":59,"user":{"displayName":"srilatha mathangi","userId":"05834365901469890006"}}},"outputs":[],"source":["total_em=0\n","total_f1=0\n","em_list=[]\n","f1_list=[]\n","val=1500\n","for i in range(1,val+1):\n","  total_em+=max((compute_exact_match(get_prediction(answer_qids[i]), answer )) for answer in get_gold_answers(examples[qid_to_example_index[answer_qids[i]]]) )\n","  total_f1+=max((F1(get_prediction(answer_qids[i]), answer)) for answer in get_gold_answers(examples[qid_to_example_index[answer_qids[i]]]) )\n","  if(i%50==0):\n","    print(str(i)+' values: '+str(total_em/i)+' '+str(total_f1/i))\n","    print()\n","\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"pmwBMN9cKBCl","executionInfo":{"status":"aborted","timestamp":1664960056423,"user_tz":-330,"elapsed":59,"user":{"displayName":"srilatha mathangi","userId":"05834365901469890006"}}},"outputs":[],"source":["itr=1000\n","a=0\n","#itr = len(answer_qids)\n","for i in range(1000):  \n","    prediction = get_prediction(answer_qids[i][:512])\n","    example = examples[qid_to_example_index[answer_qids[i]]]\n","    gold_answers = get_gold_answers(example)\n","    em_score = max((compute_exact_match(prediction, answer)) for answer in gold_answers)\n","    a+=em_score\n","print(a/itr)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"StVrd68s0pLs","executionInfo":{"status":"aborted","timestamp":1664960056424,"user_tz":-330,"elapsed":60,"user":{"displayName":"srilatha mathangi","userId":"05834365901469890006"}}},"outputs":[],"source":[]}],"metadata":{"accelerator":"GPU","colab":{"collapsed_sections":[],"provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}